
import os
import sys
import time
import logging
from urllib.parse import urljoin
import requests
from bs4 import BeautifulSoup

logger = logging.getLogger("get_api_homeworks")
if not logger.handlers:
    h = logging.StreamHandler(stream=sys.stderr)
    h.setFormatter(logging.Formatter("%(asctime)s %(levelname)s: %(message)s"))
    logger.addHandler(h)
logger.setLevel(logging.INFO)


def _find_csrf(soup):
    for name in ("_token", "csrf_token", "csrf-token", "csrf"):
        inp = soup.find("input", {"name": name})
        if inp and inp.get("value"):
            return inp["value"]
    for name in ("csrf-token", "_token", "csrf"):
        m = soup.find("meta", {"name": name})
        if m and m.get("content"):
            return m["content"]
    return None


def get_homeworks(s: requests.Session, lesson_id):
    print('get_homeworks is working')
    domain = os.getenv("API_DOMAIN")
    if not domain:
        raise RuntimeError("API_DOMAIN is not set")

    email = os.getenv("API_ACCOUNT_EMAIL")
    pwd = os.getenv("API_ACCOUNT_PASSWORD")
    module_id = os.getenv("MODULE_ID")

    logger.info("get_homeworks: domain=%s lesson_id=%s module_id=%s", domain, lesson_id, module_id)

    login_url = f"https://{domain}/login"
    headers = {"User-Agent": "Mozilla/5.0"}

    logger.info("GET %s", login_url)
    login_page = s.get(login_url, headers=headers, timeout=15)
    soup = BeautifulSoup(login_page.text, "html.parser")

    # –∏—â–µ–º —Ñ–æ—Ä–º—É –≤—Ö–æ–¥–∞
    login_form = None
    for f in soup.find_all("form"):
        if f.find("input", {"type": "password"}):
            login_form = f
            break
    if not login_form:
        forms = soup.find_all("form")
        if forms:
            login_form = forms[0]

    payload = {}
    if login_form:
        for inp in login_form.find_all("input"):
            name = inp.get("name")
            if not name:
                continue
            payload[name] = inp.get("value", "")

        keys = list(payload.keys())

        def pick(keys, candidates):
            for k in keys:
                lk = k.lower()
                for c in candidates:
                    if c in lk:
                        return k
            return None

        email_field = pick(keys, ["email", "e-mail", "login", "user", "username"]) or "email"
        password_field = pick(keys, ["password", "pass"]) or None
        if not password_field:
            pwd_input = login_form.find("input", {"type": "password"})
            if pwd_input and pwd_input.get("name"):
                password_field = pwd_input.get("name")
        if not password_field:
            password_field = "password"

        payload[email_field] = email or ""
        payload[password_field] = pwd or ""

        action = login_form.get("action") or "/login"
        action = urljoin(login_url, action)
        method = (login_form.get("method") or "post").lower()
    else:
        csrf = _find_csrf(soup)
        payload = {"email": email or "", "password": pwd or ""}
        action = f"https://{domain}/login"
        method = "post"
        if csrf:
            headers["X-CSRF-TOKEN"] = csrf

    logger.info("Submitting login to %s (method=%s)", action, method)
    if method == "post":
        login_resp = s.post(action, data=payload, headers={**headers, "Referer": login_url}, timeout=15)
    else:
        login_resp = s.get(action, params=payload, headers={**headers, "Referer": login_url}, timeout=15)

    logger.info("Login final url: %s status: %s", getattr(login_resp, "url", None), getattr(login_resp, "status_code", None))

    student_live_url = f"https://{domain}/student_live/index"
    params = {
        "email": "",
        "full_name": "",
        "hidden_last_name": "",
        "hidden_first_name": "",
        "hidden_mid_name": "",
        "vk_id": "",
        "subject_id": "20",
        "course_id": "1856",
        "module_id": module_id,
        "lesson_id": lesson_id,
    }

    parsed = []

    # -----------------------------
    # üîπ –≤–æ—Ç —Ç—É—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –∏–º–µ–Ω–∞–º
    # -----------------------------
    target_names = [


        "–î–º–∏—Ç—Ä–∏–π –ü–æ—Å—Ç–Ω–æ–≤", "–ù–∏–∫–∏—Ç–∞ –ú–æ—Ä–æ–∑–æ–≤", "–î–∏–º–∞ –ë–µ—Å–æ–≥–æ–Ω–æ–≤", "–ü–æ–ª–∏–Ω–∞ –°–æ–Ω", "–ï–≥–æ—Ä –ü–∞—Ä–±—É–∑–∏–Ω",
        "–î–∞–Ω–∏–∏–ª –õ—É—á–∫–æ", "–¢–∏–º—É—Ä –ú–∞—Ö–º—É–¥–æ–≤", "–î–µ–Ω–∏—Å –ì–∞–Ω–∞–≥–∏–Ω", "–ò–≤–∞–Ω –†–æ–º–∞–Ω–æ–≤", "–î–º–∏—Ç—Ä–∏–π –ù–æ—Ä–º–æ–≤",
        "–ò–≤–∞–Ω –®–∏–≥–∞–Ω–æ–≤", "–ê–Ω–∞—Å—Ç–∞—Å–∏—è –ñ–∏—Ö–∞—Ä–µ–≤–∞", "–∞—Ä–∏–Ω–∞ –∫–æ–Ω–≤–∏—Å–∞—Ä", "–í–∏–∫—Ç–æ—Ä–∏—è –ê—Ö—É–Ω–æ–≤–∞",
        "–°–æ—Ñ—å—è –®–∏—à–∫–∏–Ω–∞", "–¢–∏–º—É—Ä –Æ–ª–¥–∞—à–µ–≤", "–ö–∏—Ä–∏–ª–ª –ì–Ω—É—Å–æ–≤", "–ê–ª–∏–Ω–∞ –ö–æ–ª–æ—Å–∫–æ–≤–∞", "–ü–æ–ª–∏–Ω–∫–∞ –ö–∞—à–∏—Ä—Å–∫–∞—è",
        "–ê–ª–µ–∫—Å–µ–π –õ–∏–ø—Å–∫–∏–π", "–ì–∞–∞–∫ –†–æ–º–∞–Ω –í–∏—Ç–∞–ª—å–µ–≤–∏—á", "–ó–æ—Ä—á–µ–Ω–∫–æ –î–∞–Ω–∏–ª–∞ –°–µ—Ä–≥–µ–µ–≤–∏—á",
        "Vlada Kalinskaya", "–°–æ—Ñ–∞ –ú–∞—Ä—Ç—ã–Ω–æ–≤–∞", "–°—Ç–µ–ø–∞–Ω –ß—É–≥—É–Ω–æ–≤", "–ì–æ—Ä–± –í–µ—Ä–æ–Ω–∏–∫–∞ –ê–ª–µ–∫—Å–∞–Ω–¥—Ä–æ–≤–Ω–∞",
        "–®—É–π—Å–∫–∞—è –ò—Ä–∏–Ω–∞ –í—è—á–µ—Å–ª–∞–≤–æ–≤–Ω–∞", "Egor Averchenkov", "–ê–π—Å—ë–Ω–∞ –°–≤–µ—Ç–ª–æ–≤–∞", "Nikita Ageev",
        "–ê–ª–ª–∞ –ú–∞—Ä—É—â–∞–∫", "–ë–µ–∫—Ç–∞–≥–∏—Ä–æ–≤ –î–∞–Ω–∏—è–ª –¢–∞–≥–∏—Ä–æ–≤–∏—á", "„É¥„Ç©„Ç§„Ç∑„É¢„Ç§ „Éì„É©„ÇØ„Éà„ÉÉ„Éà", "–í–∞–ª–µ—Ä–∏—è –¢—É—Ä–æ–≤—Å–∫–∞—è","–í–∏–∫–∞ –§—Ä–∏—Ü–ª–µ—Ä"
    ]

    for name in target_names:
        params["full_name"] = name
        logger.info("Fetching student_live for %s", name)
        resp_one = s.get(student_live_url, params=params, headers=headers, timeout=15)
        s2 = BeautifulSoup(resp_one.text, "html.parser")
        tbody = s2.find("tbody", id="student_lives_body")
        if not tbody:
            continue

        for tr in tbody.find_all("tr"):
            tds = tr.find_all("td")
            if len(tds) < 3:
                continue
            student_name = tds[2].get_text(strip=True)
            if student_name != name:
                continue

            for a in tr.find_all("a", href=True):
                href = a["href"]
                if "student_live/tasks" not in href:
                    continue
                spans = [sp.get_text(strip=True) for sp in a.find_all("span")]
                b = tr.find("b", attrs={"data-datetime": True})
                dt = b.get("data-datetime") if b else None
                parsed.append((href, spans, dt))

        time.sleep(0.3)  # –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏, —á—Ç–æ–±—ã –Ω–µ –∑–∞–¥–¥–æ—Å–∏—Ç—å

    # -----------------------------
    logger.info("Parsed %d homework links", len(parsed))
    try:
        setattr(resp_one, "parsed_homeworks", parsed)
    except Exception:
        logger.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏—Å–≤–æ–∏—Ç—å parsed_homeworks –∫ Response –æ–±—ä–µ–∫—Ç—É")

    return resp_one
